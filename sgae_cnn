import torch
import torch.nn as nn
import torch.nn.functional as F

# Sparse Gated Autoencoder Module
class SparseGatedAutoEncoder(nn.Module):
    def __init__(self, input_dim, hidden_dim, sparsity_lambda=0.05):
        super(SparseGatedAutoEncoder, self).__init__()
        self.encoder = nn.Linear(input_dim, hidden_dim)
        self.decoder = nn.Linear(hidden_dim, input_dim)
        self.sparsity_lambda = sparsity_lambda

    def forward(self, x):
        z = torch.tanh(self.encoder(x))  # Sparse encoding
        sparse_loss = self.sparsity_lambda * torch.mean(torch.abs(z))  # Enforce sparsity
        
        x_recon = self.decoder(z)  # Reconstruct input
        return x_recon, z, sparse_loss

# 1D CNN Model with SGAE as First Layer
class SGAE_CNN(nn.Module):
    def __init__(self, spectral_bands, sgae_hidden_dim, cnn_channels):
        super(SGAE_CNN, self).__init__()
        
        # Sparse Gated Autoencoder (Feature Selection)
        self.sgae = SparseGatedAutoEncoder(spectral_bands, sgae_hidden_dim)
        
        # 1D CNN Layers
        self.conv1 = nn.Conv1d(in_channels=1, out_channels=cnn_channels, kernel_size=5, padding=2)
        self.conv2 = nn.Conv1d(cnn_channels, cnn_channels * 2, kernel_size=3, padding=1)
        self.pool = nn.MaxPool1d(2)  # Reduce spectral dimension
        
        # Fully Connected Classifier
        self.fc = nn.Linear((cnn_channels * 2) * (sgae_hidden_dim // 2), 10)  # Assuming 10 classes

    def forward(self, x):
        x_recon, sparse_rep, sparse_loss = self.sgae(x)  # Sparse representation
        
        x = sparse_rep.unsqueeze(1)  # Reshape to (Batch, Channels=1, Spectral Bands)
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        
        x = x.view(x.shape[0], -1)  # Flatten for classification
        x = self.fc(x)
        
        return x, sparse_loss, sparse_rep  # Output classification, sparse loss, and sparse features
